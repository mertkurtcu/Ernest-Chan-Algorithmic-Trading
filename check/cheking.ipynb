{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Mean Reversion\n",
    "\n",
    "Mean reversion is a trading strategy positing that asset prices and returns tend to revert to their long-term mean or average level over time. Mathematically, such a continuous-time series is represented by an Ornstein-Uhlenbeck process, where the change in price series in the next period is proportional to the difference between the mean price and the current price. In contrast, a random walk, or Brownian motion, where current price movements are independent of historical data, lacks the \"memory\" of its previous states at any given moment in time. The mean-reverting characteristic of such time series can be leveraged to design and implement profitable trading strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dickey-Fuller (ADF) Test\n",
    "\n",
    "The Augmented Dickey-Fuller (ADF) test is a statistical test used to determine whether a given time series is stationary or not. A stationary time series has properties that do not depend on the time at which the series is observed; specifically, its mean, variance, and autocorrelation structure remain constant over time. The ADF test is used to test for the presence of a unit root.\n",
    "\n",
    "## Basic Model\n",
    "\n",
    "The basic Dickey-Fuller test can be represented by the following autoregressive model:\n",
    "\n",
    "$y_t = \\rho y_{t-1} + \\epsilon_t$\n",
    "\n",
    "where:\n",
    "- $y_t$ is the time series observation,\n",
    "- $\\epsilon_t$ is the white noise error term.\n",
    "\n",
    "## Augmentation\n",
    "\n",
    "To account for higher-order autoregressive processes and improve the test's robustness, the ADF test uses an augmented model that includes lagged differences of $y_t$:\n",
    "\n",
    "$\\Delta y_t = \\alpha + \\beta t + \\rho y_{t-1} + \\sum_{i=1}^p \\phi_i \\Delta y_{t-i} + \\epsilon_t$\n",
    "\n",
    "where:\n",
    "- $\\Delta y_t = y_t - y_{t-1}$ is the first difference of $y_t$,\n",
    "- $\\alpha$ is the constant term,\n",
    "- $\\beta t$ represents the trend term (optional),\n",
    "- $\\rho$ is the coefficient on the lagged level of the time series,\n",
    "- $\\phi_i$ are coefficients for the lagged differences,\n",
    "- $p$ is the number of lagged differences included,\n",
    "- $\\epsilon_t$ is the error term.\n",
    "\n",
    "## Hypotheses\n",
    "\n",
    "- **Null Hypothesis (H0)**: $\\rho = 0$. This implies that the time series has a unit root and is non-stationary.\n",
    "- **Alternative Hypothesis (H1)**: $\\rho < 0$. This implies that the time series is stationary.\n",
    "\n",
    "## Test Statistic\n",
    "\n",
    "The test statistic for the ADF test is derived from the estimated value of $\\rho$. Specifically, we estimate the model and obtain the coefficient $\\hat{\\rho}$ on $y_{t-1}$. The test statistic is:\n",
    "\n",
    "$\\text{ADF Statistic} = \\frac{\\hat{\\rho} - 1}{\\text{SE}(\\hat{\\rho})}$\n",
    "\n",
    "where $\\text{SE}(\\hat{\\rho})$ is the standard error of the $\\hat{\\rho}$ estimate.\n",
    "\n",
    "## Critical Values\n",
    "\n",
    "The calculated ADF statistic is compared to critical values from the Dickey-Fuller distribution. These critical values vary depending on whether the model includes a constant, a trend, or neither.\n",
    "\n",
    "## Decision Rule\n",
    "\n",
    "- **If the ADF statistic is less than the critical value**: Reject the null hypothesis $H_0$, suggesting the time series is stationary.\n",
    "- **If the ADF statistic is greater than the critical value**: Fail to reject the null hypothesis $H_0$, suggesting the time series is non-stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pylab as plt\n",
    "import yfinance as yf\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ADF Statistic: -1.8043840820546124\n",
      "p-value: 0.37828730114973885\n",
      "Critical Values:\n",
      "   1%: -3.4357480073434905\n",
      "   5%: -2.863923702481129\n",
      "   10%: -2.568039121778048\n"
     ]
    }
   ],
   "source": [
    "ticker=[\"USDCAD=X\"]\n",
    "\n",
    "# Download historical data for USD/CAD using yfinance\n",
    "data = yf.download(ticker, start='2007-07-22', end='2012-03-28', interval='1d')\n",
    "\n",
    "# Select the 'Adj Close' price for the test\n",
    "close_prices = data['Adj Close'].dropna()\n",
    "\n",
    "# Perform the ADF test\n",
    "adf_result = ts.adfuller(close_prices,1)\n",
    "\n",
    "# Print the ADF test results\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f'   {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurst Exponent\n",
    "\n",
    "The **Hurst exponent** ($H$) is a statistical measure used to determine the long-term memory of time series data. It helps identify whether a time series is **persistent**, **mean-reverting**, or exhibits **random walk behavior**. \n",
    "\n",
    "\n",
    "## Formula\n",
    "\n",
    "The Hurst exponent is defined as:\n",
    "\n",
    "$\n",
    "E[R(n)/S(n)] = Cn^H\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $E[R(n)/S(n)]$ is the expected rescaled range (range of cumulative deviations divided by standard deviation) of the time series over $n$ periods.\n",
    "- $C$ is a constant.\n",
    "- $n$ is the time period.\n",
    "- $H$ is the Hurst exponent, which lies in the range $0 \\leq H \\leq 1$.\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "The value of the Hurst exponent indicates the nature of the time series:\n",
    "\n",
    "- **$H = 0.5$**: The time series follows a random walk (i.e., no autocorrelation, purely stochastic process like Brownian motion).\n",
    "- **$H < 0.5$**: The time series is **mean-reverting**. This suggests that if the time series has been increasing, it is likely to decrease in the future, and vice versa (negative autocorrelation).\n",
    "- **$H > 0.5$**: The time series is **persistent**. This implies that trends in the data are likely to continue in the same direction (positive autocorrelation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurst Exponent ['USDCAD=X'] : 0.4656101012073439\n"
     ]
    }
   ],
   "source": [
    "def hurst(ts):\n",
    "\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, 100)\n",
    "\n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [np.sqrt(np.std(np.subtract(ts[lag:], ts[:-lag]))) for lag in lags]\n",
    "\n",
    "    # Use a linear fit to estimate the Hurst Exponent\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "\n",
    "    # Return the Hurst exponent from the polyfit output\n",
    "    return poly[0]*2.0\n",
    "\n",
    "# Assuming you have run the above code to obtain 'data'!\n",
    "print(\"Hurst Exponent\",ticker,\": %s\" % hurst(data['Adj Close'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Variance-Ratio Test Results     \n",
      "=====================================\n",
      "Test Statistic                  0.548\n",
      "P-value                         0.584\n",
      "Lags                                5\n",
      "-------------------------------------\n",
      "\n",
      "Computed with overlapping blocks (de-biased)\n"
     ]
    }
   ],
   "source": [
    "from arch.unitroot import VarianceRatio\n",
    "\n",
    "vr = VarianceRatio(data['Adj Close'], 5)\n",
    "print(vr.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half-Life of Mean Reversion: 124.4706025123989\n"
     ]
    }
   ],
   "source": [
    "def calculate_half_life(series):\n",
    "    # Calculate the lagged series\n",
    "    series_lag = series.shift(1)\n",
    "    \n",
    "    # Calculate the change in the series\n",
    "    delta_series = series - series_lag\n",
    "    \n",
    "    # Remove missing values\n",
    "    series_lag = series_lag[1:]\n",
    "    delta_series = delta_series[1:]\n",
    "    \n",
    "    # Add a constant term to the lagged series\n",
    "    series_lag_constant = sm.add_constant(series_lag)\n",
    "    \n",
    "    # Fit the AR(1) model\n",
    "    model = sm.OLS(delta_series, series_lag_constant)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Get the AR(1) coefficient\n",
    "    theta = results.params.iloc[1]  # Use iloc to avoid the warning\n",
    "    \n",
    "    # Calculate the half-life\n",
    "    half_life = -np.log(2) / theta\n",
    "    \n",
    "    return half_life\n",
    "\n",
    "# Calculate half-life\n",
    "halflife = calculate_half_life(close_prices)\n",
    "print(\"Half-Life of Mean Reversion:\", halflife)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half-Life of Mean Reversion: 124.4706025123989\n"
     ]
    }
   ],
   "source": [
    "def calculate_half_life(series):\n",
    "    # Calculate the lagged series\n",
    "    series_lag = series.shift(1)\n",
    "    \n",
    "    # Calculate the change in the series\n",
    "    delta_series = series - series_lag\n",
    "    \n",
    "    # Remove missing values\n",
    "    series_lag = series_lag[1:]\n",
    "    delta_series = delta_series[1:]\n",
    "    \n",
    "    # Add a constant term to the lagged series\n",
    "    series_lag_constant = sm.add_constant(series_lag)\n",
    "    \n",
    "    # Fit the AR(1) model\n",
    "    model = sm.OLS(delta_series, series_lag_constant)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Get the AR(1) coefficient\n",
    "    theta = results.params.iloc[1]  # Use iloc to avoid the warning\n",
    "    \n",
    "    # Calculate the half-life\n",
    "    half_life = -np.log(2) / theta\n",
    "    \n",
    "    return half_life\n",
    "\n",
    "# Calculate half-life\n",
    "halflife = calculate_half_life(close_prices)\n",
    "print(\"Half-Life of Mean Reversion:\", halflife)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
